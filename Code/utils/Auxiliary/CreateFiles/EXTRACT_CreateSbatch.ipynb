{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Functions ###\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract error and time vectors\n",
    "def ExtractErrorAndTime(files):\n",
    "    error_vecs = []\n",
    "    time_vecs = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(file, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "                error_vecs.append(data[\"ErrorVec\"])\n",
    "                time_vecs.append(data[\"ElapsedTime\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file}: {e}\")\n",
    "    return np.array(error_vecs), np.array(time_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataType: BostonHousing\n",
      "ModelType: TreeFarms\n",
      "Categories: ['MTTreeFarms_UEI1_NE100_Reg0.01_RBA0.01.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Simulate argparse args object\n",
    "class Args:\n",
    "    def __init__(self, DataType, ModelType, Categories):\n",
    "        self.DataType = DataType\n",
    "        self.ModelType = ModelType\n",
    "        self.Categories = Categories\n",
    "\n",
    "# Manually setting up args\n",
    "args = Args(\n",
    "    DataType=\"BostonHousing\",\n",
    "    ModelType=\"TreeFarms\",\n",
    "    Categories='[\"MTTreeFarms_UEI1_NE100_Reg0.01_RBA0.01.pkl\"]'\n",
    ")\n",
    "\n",
    "# Parsing arguments\n",
    "data_type = args.DataType\n",
    "model_type = args.ModelType\n",
    "categories = eval(args.Categories)  # Convert string to Python list\n",
    "\n",
    "# Display arguments (for testing)\n",
    "print(\"DataType:\", data_type)\n",
    "print(\"ModelType:\", model_type)\n",
    "print(\"Categories:\", categories)\n",
    "\n",
    "# Add the main script logic below using `data_type`, `model_type`, and `categories`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"MTTreeFarms_UEI1_NE100_Reg0.01_RBA0.01.pkl\"]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Set Up ###\n",
    "cwd = os.getcwd()\n",
    "ResultsDirectory = os.path.join(cwd, \"Results\", args.DataType, args.ModelType)\n",
    "OutputDirectory = os.path.join(ResultsDirectory, \"ProcessedResults\")\n",
    "RawDirectory = os.path.join(ResultsDirectory, \"Raw\")\n",
    "Categories = json.loads(args.Categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group files by category\n",
    "category_files = {category: [] for category in Categories}\n",
    "for filename in os.listdir('/Users/simondn/Documents/RashomonActiveLearning/Results/BostonHousing/TreeFarms/Raw'):\n",
    "    if filename.endswith(\".pkl\"):\n",
    "        for category in Categories:\n",
    "            if filename.endswith(category):\n",
    "                category_files[category].append(os.path.join(RawDirectory, filename))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' .foo.png'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MTTreeFarms_UEI1_NE100_Reg0.01_RBA0.01.pkl': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process files for each category\n",
    "ErrorMatrices = {}\n",
    "TimeMatrices = {}\n",
    "\n",
    "for category, files in category_files.items():\n",
    "    if not files:\n",
    "        print(f\"Warning: No files found for category {category}. Skipping.\")\n",
    "        continue\n",
    "    print(f\"Processing category: {category} with {len(files)} files\")\n",
    "    error_vecs, time_vecs = ExtractErrorAndTime(files)\n",
    "    ErrorMatrices[category] = error_vecs  # Transpose\n",
    "    TimeMatrices[category] = time_vecs    # Transpose\n",
    "\n",
    "# Retain original category names as keys\n",
    "ErrorMatrices = {category: ErrorMatrices[category] for category in category_files if category in ErrorMatrices}\n",
    "TimeMatrices = {category: TimeMatrices[category] for category in category_files if category in TimeMatrices}\n",
    "ErrorMatrices = {key.replace(\".pkl\", \"\"): value for key, value in ErrorMatrices.items()}\n",
    "TimeMatrices = {key.replace(\".pkl\", \"\"): value for key, value in TimeMatrices.items()}\n",
    "\n",
    "# Squeeze dimensions #\n",
    "ErrorMatrices = {key: matrix.squeeze() for key, matrix in ErrorMatrices.items()}\n",
    "TimeMatrices = {key: matrix.squeeze() for key, matrix in TimeMatrices.items()}\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(OutputDirectory, exist_ok=True)\n",
    "\n",
    "# Save ErrorMatrices\n",
    "for key, matrix in ErrorMatrices.items():\n",
    "    df = pd.DataFrame(matrix)  # Convert to DataFrame\n",
    "    df.to_csv(os.path.join(OutputDirectory, f\"{key}_ErrorMatrix.csv\"), index=False)\n",
    "\n",
    "# Save TimeMatrices\n",
    "for key, matrix in TimeMatrices.items():\n",
    "    df = pd.DataFrame(matrix)  # Convert to DataFrame\n",
    "    df.to_csv(os.path.join(OutputDirectory, f\"{key}_TimeMatrix.csv\"), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
