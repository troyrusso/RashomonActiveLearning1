{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataType: BostonHousingBinned\n",
      "ModelType: TreeFarms\n",
      "Categories: ['8_STTreeEnsembleQBC_MTTreeFarms_UEI0_RashomonNum100.pkl', '8_STTreeEnsembleQBC_MTTreeFarms_UEI0_RashomonNum10.pkl', '8_STTreeEnsembleQBC_MTTreeFarms_UEI1_RashomonNum100.pkl', '8_STTreeEnsembleQBC_MTTreeFarms_UEI1_RashomonNum10.pkl']\n",
      "Processing category: 8_STTreeEnsembleQBC_MTTreeFarms_UEI0_RashomonNum100.pkl with 98 files\n",
      "Processing category: 8_STTreeEnsembleQBC_MTTreeFarms_UEI0_RashomonNum10.pkl with 97 files\n",
      "Processing category: 8_STTreeEnsembleQBC_MTTreeFarms_UEI1_RashomonNum100.pkl with 98 files\n",
      "Processing category: 8_STTreeEnsembleQBC_MTTreeFarms_UEI1_RashomonNum10.pkl with 98 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to extract error and time vectors\n",
    "def ExtractErrorAndTime(files):\n",
    "    error_vecs = []\n",
    "    time_vecs = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(file, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "                error_vecs.append(data[\"ErrorVec\"])\n",
    "                time_vecs.append(data[\"ElapsedTime\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file}: {e}\")\n",
    "    return np.array(error_vecs), np.array(time_vecs)\n",
    "\n",
    "# Manually set the arguments\n",
    "args = argparse.Namespace(\n",
    "    DataType=\"BostonHousingBinned\",\n",
    "    ModelType=\"TreeFarms\",\n",
    "    Categories=json.dumps([\n",
    "        \"8_STTreeEnsembleQBC_MTTreeFarms_UEI0_RashomonNum100.pkl\",\n",
    "        \"8_STTreeEnsembleQBC_MTTreeFarms_UEI0_RashomonNum10.pkl\",\n",
    "        \"8_STTreeEnsembleQBC_MTTreeFarms_UEI1_RashomonNum100.pkl\",\n",
    "        \"8_STTreeEnsembleQBC_MTTreeFarms_UEI1_RashomonNum10.pkl\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Access arguments as you would in the original script\n",
    "print(\"DataType:\", args.DataType)\n",
    "print(\"ModelType:\", args.ModelType)\n",
    "print(\"Categories:\", json.loads(args.Categories))\n",
    "\n",
    "# ### Set Up ###\n",
    "cwd = \"/Users/simondn/Documents/RashomonActiveLearning/\"\n",
    "ResultsDirectory = os.path.join(cwd, \"Results\", args.DataType, args.ModelType)\n",
    "OutputDirectory = os.path.join(ResultsDirectory, \"ProcessedResults\")\n",
    "RawDirectory = os.path.join(ResultsDirectory, \"Raw\")\n",
    "Categories = json.loads(args.Categories)\n",
    "\n",
    "# # Command-line argument parser\n",
    "# parser = argparse.ArgumentParser(description=\"Aggregate simulation results.\")\n",
    "# parser.add_argument(\"--DataType\", type=str, required=True, help=\"Type of data.\")\n",
    "# parser.add_argument(\"--ModelType\", type=str, required=True, help=\"Prediction model type.\")\n",
    "# parser.add_argument(\"--Categories\", type=str, required=True, help=\"Comma-separated list of categories.\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# ### Set Up ###\n",
    "# cwd = os.getcwd()\n",
    "# ResultsDirectory = os.path.join(cwd, \"Results\", args.DataType, args.ModelType)\n",
    "# OutputDirectory = os.path.join(ResultsDirectory, \"ProcessedResults\")\n",
    "# RawDirectory = os.path.join(ResultsDirectory, \"Raw\")\n",
    "# Categories = json.loads(args.Categories)\n",
    "\n",
    "\n",
    "# Group files by category\n",
    "category_files = {category: [] for category in Categories}\n",
    "for filename in os.listdir(RawDirectory):\n",
    "    if filename.endswith(\".pkl\"):\n",
    "        for category in Categories:\n",
    "            if filename.endswith(category):\n",
    "                category_files[category].append(os.path.join(RawDirectory, filename))\n",
    "                break\n",
    "\n",
    "\n",
    "# Process files for each category\n",
    "ErrorMatrices = {}\n",
    "TimeMatrices = {}\n",
    "\n",
    "for category, files in category_files.items():\n",
    "    if not files:\n",
    "        print(f\"Warning: No files found for category {category}. Skipping.\")\n",
    "        continue\n",
    "    print(f\"Processing category: {category} with {len(files)} files\")\n",
    "    error_vecs, time_vecs = ExtractErrorAndTime(files)\n",
    "    ErrorMatrices[category] = error_vecs  # Transpose\n",
    "    TimeMatrices[category] = time_vecs    # Transpose\n",
    "\n",
    "\n",
    "# Retain original category names as keys\n",
    "ErrorMatrices = {category: ErrorMatrices[category] for category in category_files if category in ErrorMatrices}\n",
    "TimeMatrices = {category: TimeMatrices[category] for category in category_files if category in TimeMatrices}\n",
    "ErrorMatrices = {key.replace(\".pkl\", \"\"): value for key, value in ErrorMatrices.items()}\n",
    "TimeMatrices = {key.replace(\".pkl\", \"\"): value for key, value in TimeMatrices.items()}\n",
    "\n",
    "\n",
    "# Squeeze dimensions #\n",
    "ErrorMatrices = {key: matrix.squeeze() for key, matrix in ErrorMatrices.items()}\n",
    "TimeMatrices = {key: matrix.squeeze() for key, matrix in TimeMatrices.items()}\n",
    "\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(OutputDirectory, exist_ok=True)\n",
    "\n",
    "# Save ErrorMatrices\n",
    "for key, matrix in ErrorMatrices.items():\n",
    "    df = pd.DataFrame(matrix)  # Convert to DataFrame\n",
    "    df.to_csv(os.path.join(OutputDirectory, f\"{key}_ErrorMatrix.csv\"), index=False)\n",
    "\n",
    "# Save TimeMatrices\n",
    "for key, matrix in TimeMatrices.items():\n",
    "    df = pd.DataFrame(matrix)  # Convert to DataFrame\n",
    "    df.to_csv(os.path.join(OutputDirectory, f\"{key}_TimeMatrix.csv\"), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
