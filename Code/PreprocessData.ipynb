{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Packages ###\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # [Auto MPG](https://archive.ics.uci.edu/dataset/9/auto+mpg) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Response: mpg (continuous)\n",
    "\n",
    "Covariates: displacement, Y, cylinders, horsepower, weight, acceleration, model_year, origin -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up ###\n",
    "labels = [\"low\", \"medium\", \"high\"]\n",
    "\n",
    "### Import data ###\n",
    "Auto = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/Data/raw/Auto.data\", delim_whitespace= True, header=None)\n",
    "Auto.columns = [\"Y\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\", \"name\"]\n",
    "Auto.drop('name', axis=1, inplace=True)\n",
    "Auto = Auto[Auto[\"horsepower\"] != \"?\"]\n",
    "Auto = Auto.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Discretize data ###\n",
    "labels = [1,2,3]\n",
    "Auto[\"displacement\"] = pd.qcut(Auto[\"displacement\"], len(labels), labels=labels)\n",
    "Auto[\"cylinders\"] = pd.qcut(Auto[\"cylinders\"], len(labels), labels=labels)\n",
    "Auto[\"horsepower\"] = pd.qcut(pd.to_numeric(Auto[\"horsepower\"]), len(labels), labels=labels)\n",
    "Auto[\"weight\"] = pd.qcut(Auto[\"weight\"], len(labels), labels=labels)\n",
    "Auto[\"acceleration\"] = pd.qcut(Auto[\"acceleration\"], len(labels), labels=labels)\n",
    "Auto[\"model_year\"] = pd.qcut(Auto[\"model_year\"], len(labels), labels=labels)\n",
    "Auto[\"origin\"] = pd.Categorical(Auto[\"origin\"])\n",
    "\n",
    "### One-hot encoding ###\n",
    "categorical_columns = [\"displacement\", \"cylinders\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\"]\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None) \n",
    "encoded = encoder.fit_transform(Auto[categorical_columns])\n",
    "encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoded_columns)\n",
    "Auto_OneHot = pd.concat(encoded_df, [Auto[\"Y\"].reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/AutoBinned.pkl', 'wb') as file:\n",
    "        pickle.dump(Auto, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # [Boston Housing](/Users/simondn/Documents/RashomonActiveLearning/Data/raw/BostonHousing.data) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import ###\n",
    "BostonHousing = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/Data/raw/BostonHousing.data\", header = None, sep='\\s+')\n",
    "BostonHousing.columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
    "BostonHousing.rename(columns={'MEDV': 'Y'}, inplace=True)\n",
    "\n",
    "### Discretize data ###\n",
    "labels = [1,2,3]\n",
    "BostonHousing[\"CRIM\"] = pd.qcut(BostonHousing[\"CRIM\"], len(labels), labels=labels)\n",
    "BostonHousing[\"ZN\"] = pd.Categorical(BostonHousing[\"ZN\"])\n",
    "BostonHousing[\"INDUS\"] = pd.qcut(pd.to_numeric(BostonHousing[\"INDUS\"]), len(labels), labels=labels)\n",
    "BostonHousing[\"CHAS\"] = pd.Categorical(BostonHousing[\"CHAS\"])\n",
    "BostonHousing[\"NOX\"] = pd.qcut(BostonHousing[\"NOX\"], len(labels), labels=labels)\n",
    "BostonHousing[\"RM\"] = pd.qcut(BostonHousing[\"RM\"], len(labels), labels=labels)\n",
    "BostonHousing[\"AGE\"] = pd.qcut(BostonHousing[\"AGE\"], len(labels), labels=labels)\n",
    "BostonHousing[\"DIS\"] = pd.qcut(BostonHousing[\"DIS\"], len(labels), labels=labels)\n",
    "BostonHousing[\"RAD\"] = pd.qcut(BostonHousing[\"RAD\"], len(labels), labels=labels)\n",
    "BostonHousing[\"TAX\"] = pd.qcut(BostonHousing[\"TAX\"], len(labels), labels=labels)\n",
    "BostonHousing[\"PTRATIO\"] = pd.qcut(BostonHousing[\"PTRATIO\"], len(labels), labels=labels)\n",
    "BostonHousing[\"B\"] = pd.qcut(BostonHousing[\"B\"], len(labels), labels=labels)\n",
    "BostonHousing[\"LSTAT\"] = pd.qcut(BostonHousing[\"LSTAT\"], len(labels), labels=labels)\n",
    "BostonHousing[\"Y\"] = pd.qcut(BostonHousing[\"Y\"], 2, labels=[1,2])\n",
    "BostonHousing[\"Y\"] = BostonHousing[\"Y\"] >= np.quantile(BostonHousing[\"Y\"], 0.75)\n",
    "\n",
    "### Filter out ###\n",
    "# KeepColumns = [\"CRIM\", \"NOX\", \"RM\", \"PTRATIO\", \"LSTAT\", \"Y\"] # Top 5\n",
    "KeepColumns = [\"CRIM\", \"NOX\", \"RM\", \"PTRATIO\", \"LSTAT\", \"TAX\", \"DIS\", \"Y\"] # Top 7\n",
    "# KeepColumns = [\"CRIM\", \"NOX\", \"RM\", \"PTRATIO\", \"LSTAT\", \"TAX\", \"DIS\", \"AGE\", \"RAD\", \"Y\"] # Top 9\n",
    "BostonHousing = BostonHousing[KeepColumns]\n",
    "\n",
    "## One-hot encoding ###\n",
    "categorical_columns = KeepColumns.copy()\n",
    "categorical_columns.remove(\"Y\")\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None) \n",
    "encoded = encoder.fit_transform(BostonHousing[categorical_columns])\n",
    "encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoded_columns)\n",
    "BostonHousing_OneHot = pd.concat([encoded_df, BostonHousing[\"Y\"].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM_1</th>\n",
       "      <th>CRIM_2</th>\n",
       "      <th>CRIM_3</th>\n",
       "      <th>NOX_1</th>\n",
       "      <th>NOX_2</th>\n",
       "      <th>NOX_3</th>\n",
       "      <th>RM_1</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>PTRATIO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>LSTAT_1</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>TAX_1</th>\n",
       "      <th>TAX_2</th>\n",
       "      <th>TAX_3</th>\n",
       "      <th>DIS_1</th>\n",
       "      <th>DIS_2</th>\n",
       "      <th>DIS_3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRIM_1  CRIM_2  CRIM_3  NOX_1  NOX_2  NOX_3  RM_1  RM_2  RM_3  PTRATIO_1  \\\n",
       "0     1.0     0.0     0.0    0.0    1.0    0.0   0.0   0.0   1.0        1.0   \n",
       "1     1.0     0.0     0.0    1.0    0.0    0.0   0.0   1.0   0.0        1.0   \n",
       "2     1.0     0.0     0.0    1.0    0.0    0.0   0.0   0.0   1.0        1.0   \n",
       "3     1.0     0.0     0.0    1.0    0.0    0.0   0.0   0.0   1.0        0.0   \n",
       "4     1.0     0.0     0.0    1.0    0.0    0.0   0.0   0.0   1.0        0.0   \n",
       "\n",
       "   ...  LSTAT_1  LSTAT_2  LSTAT_3  TAX_1  TAX_2  TAX_3  DIS_1  DIS_2  DIS_3  \\\n",
       "0  ...      1.0      0.0      0.0    1.0    0.0    0.0    0.0    1.0    0.0   \n",
       "1  ...      0.0      1.0      0.0    1.0    0.0    0.0    0.0    0.0    1.0   \n",
       "2  ...      1.0      0.0      0.0    1.0    0.0    0.0    0.0    0.0    1.0   \n",
       "3  ...      1.0      0.0      0.0    1.0    0.0    0.0    0.0    0.0    1.0   \n",
       "4  ...      1.0      0.0      0.0    1.0    0.0    0.0    0.0    0.0    1.0   \n",
       "\n",
       "      Y  \n",
       "0  True  \n",
       "1  True  \n",
       "2  True  \n",
       "3  True  \n",
       "4  True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonHousing_OneHot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from treeFarms.treefarms.model.treefarms import TREEFARMS\n",
    "# TreeFarmsModel = TREEFARMS({\"regularization\": 0.01, \"rashomon_bound_multiplier\": 0.05})\n",
    "# TreeFarmsModel.fit(BostonHousing_OneHot.loc[:, BostonHousing_OneHot.columns != \"Y\"], BostonHousing_OneHot[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/BostonHousingBinned7.pkl', 'wb') as file:\n",
    "    pickle.dump(BostonHousing_OneHot, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # [COMPAS](https://github.com/ubc-systopia/treeFarms/tree/main/experiments/datasets/compas) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/BostonHousingBinned.pkl', 'rb') as file:\n",
    "#     test1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/MONK1.pkl', 'rb') as file:\n",
    "#     test1 = pickle.load(file).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex:Female                  int64\n",
       "age:<21                     int64\n",
       "age:<23                     int64\n",
       "age:<26                     int64\n",
       "age:<46                     int64\n",
       "juvenile-felonies:=0        int64\n",
       "juvenile-misdemeanors:=0    int64\n",
       "juvenile-crimes:=0          int64\n",
       "priors:=0                   int64\n",
       "priors:=1                   int64\n",
       "priors:2-3                  int64\n",
       "priors:>3                   int64\n",
       "Y                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPAS = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/treeFarms/experiments/datasets/compas/binned.csv\")\n",
    "# COMPAS.rename(columns={'recidivate-within-two-years:1': 'Y'}, inplace=True)\n",
    "\n",
    "# ### Save ###\n",
    "# # with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/COMPAS.pkl', 'wb') as file:\n",
    "#     # pickle.dump(COMPAS, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # [MONK](https://github.com/ubc-systopia/treeFarms/tree/main/experiments/datasets)  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Read in columns ###\n",
    "# MONK1 = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/Data/raw/MONK1.csv\",delimiter=\",\", header = 0)\n",
    "# MONK2 = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/Data/raw/MONK2.csv\",delimiter=\",\", header = 0)\n",
    "# MONK3 = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/Data/raw/MONK3.csv\",delimiter=\",\", header = 0)\n",
    "\n",
    "# ### Rename columns ###\n",
    "# MONK1.rename(columns={'class_1': 'Y'}, inplace=True)\n",
    "# MONK2.rename(columns={'class_1': 'Y'}, inplace=True)\n",
    "# MONK3.rename(columns={'class_1': 'Y'}, inplace=True)\n",
    "\n",
    "# # ### Change to categorical ###\n",
    "# # MONK1 = MONK1.astype('bool')\n",
    "# # MONK2 = MONK2.astype('bool')\n",
    "# # MONK3 = MONK3.astype('bool')\n",
    "\n",
    "# ### Move columns ###\n",
    "# MONK1 = MONK1.reindex(columns=['Y', 'a1_1', 'a1_2', 'a2_1', 'a2_2', 'a3_1', 'a4_1', 'a4_2', 'a5_1', 'a5_2', 'a5_3', 'a6_1',])\n",
    "# MONK2 = MONK2.reindex(columns=['Y', 'a1_1', 'a1_2', 'a2_1', 'a2_2', 'a3_1', 'a4_1', 'a4_2', 'a5_1', 'a5_2', 'a5_3', 'a6_1',])\n",
    "# MONK3 = MONK3.reindex(columns=['Y', 'a1_1', 'a1_2', 'a2_1', 'a2_2', 'a3_1', 'a4_1', 'a4_2', 'a5_1', 'a5_2', 'a5_3', 'a6_1',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Save files ###\n",
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/MONK1.pkl', 'wb') as file:\n",
    "#         pickle.dump(MONK1, file)\n",
    "\n",
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/MONK2.pkl', 'wb') as file:\n",
    "#         pickle.dump(MONK2, file)\n",
    "\n",
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/MONK3.pkl', 'wb') as file:\n",
    "#         pickle.dump(MONK3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/MONK1.pkl', 'rb') as file:\n",
    "#     test1 = pickle.load(file).dropna()\n",
    "\n",
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/MONK2.pkl', 'rb') as file:\n",
    "#     test2 = pickle.load(file).dropna()\n",
    "\n",
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/MONK3.pkl', 'rb') as file:\n",
    "#     test3 = pickle.load(file).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Iris -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load Iris Data ###\n",
    "# from sklearn.datasets import load_iris\n",
    "# iris = load_iris()\n",
    "\n",
    "# ### Covariates ###\n",
    "# X = pd.DataFrame(iris['data'])\n",
    "# X.columns = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
    "\n",
    "# ### Response ###\n",
    "# y = pd.DataFrame(iris[\"target\"])\n",
    "# y.columns = [\"Y\"]\n",
    "# y['Y'] = y['Y'].astype(\"category\")\n",
    "\n",
    "# ### Discretize data ###\n",
    "# labels = [1,2,3]\n",
    "# X[\"SepalLength\"] = pd.qcut(X[\"SepalLength\"], len(labels), labels=labels)\n",
    "# X[\"SepalWidth\"] = pd.qcut(X[\"SepalWidth\"], len(labels), labels=labels)\n",
    "# X[\"PetalLength\"] = pd.qcut(X[\"PetalLength\"], len(labels), labels=labels)\n",
    "# X[\"PetalWidth\"] = pd.qcut(X[\"PetalWidth\"], len(labels), labels=labels)\n",
    "\n",
    "# ### One-hot encoding ###\n",
    "# categorical_columns = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
    "# encoder = OneHotEncoder(sparse_output=False, drop=None) \n",
    "# encoded = encoder.fit_transform(X[categorical_columns])\n",
    "# encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "# encoded_df = pd.DataFrame(encoded, columns=encoded_columns)\n",
    "# Iris_OneHot = pd.concat([encoded_df, y[\"Y\"].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/Iris.pkl', 'wb') as file:\n",
    "        pickle.dump(Iris_OneHot, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # [Heart Disease](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset?resource=download) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HeartDisease = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/Data/raw/heart.csv\")\n",
    "# HeartDisease.rename(columns={'target': 'Y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Discretize data ###\n",
    "# labels = [1,2,3]\n",
    "# HeartDisease[\"age\"] = pd.qcut(HeartDisease[\"age\"], len(labels), labels=labels)\n",
    "# HeartDisease[\"sex\"] = pd.Categorical(HeartDisease[\"sex\"])\n",
    "# HeartDisease[\"cp\"] = pd.Categorical(HeartDisease[\"cp\"])\n",
    "# HeartDisease[\"trestbps\"] = pd.qcut(HeartDisease[\"trestbps\"], len(labels), labels=labels)\n",
    "# HeartDisease[\"chol\"] = pd.qcut(HeartDisease[\"chol\"], len(labels), labels=labels)\n",
    "# HeartDisease[\"fbs\"] = pd.Categorical(HeartDisease[\"fbs\"])\n",
    "# HeartDisease[\"restecg\"] = pd.Categorical(HeartDisease[\"restecg\"])\n",
    "# HeartDisease[\"thalach\"] = pd.qcut(HeartDisease[\"thalach\"], len(labels), labels=labels)\n",
    "# HeartDisease[\"exang\"] = pd.Categorical(HeartDisease[\"exang\"])\n",
    "# HeartDisease[\"oldpeak\"] = pd.qcut(HeartDisease[\"oldpeak\"], len(labels), labels=labels)\n",
    "# HeartDisease[\"slope\"] = pd.Categorical(HeartDisease[\"slope\"])\n",
    "# HeartDisease[\"ca\"] = pd.Categorical(HeartDisease[\"ca\"])\n",
    "# HeartDisease[\"thal\"] = pd.Categorical(HeartDisease[\"thal\"])\n",
    "# HeartDisease[\"Y\"] = pd.Categorical(HeartDisease[\"Y\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### One-hot encoding ###\n",
    "# categorical_columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"]\n",
    "# encoder = OneHotEncoder(sparse_output=False, drop=None) \n",
    "# encoded = encoder.fit_transform(HeartDisease[categorical_columns])\n",
    "# encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "# encoded_df = pd.DataFrame(encoded, columns=encoded_columns)\n",
    "# HeartDisease_OneHot = pd.concat([encoded_df, HeartDisease[\"Y\"].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from treeFarms.treefarms.model.treefarms import TREEFARMS\n",
    "TreeFarmsModel = TREEFARMS({\"regularization\": 0.01, \"rashomon_bound_multiplier\": 0.05})\n",
    "TreeFarmsModel.fit(HeartDisease_OneHot.loc[:, HeartDisease_OneHot.columns != \"Y\"], HeartDisease_OneHot[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # [Pima Indians Diabetes](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load data ###\n",
    "# PimaIndians = pd.read_csv(\"/Users/simondn/Documents/RashomonActiveLearning/Data/raw/PimaIndiansDiabetes.csv\")\n",
    "# PimaIndians.rename(columns={'Outcome': 'Y'}, inplace=True)\n",
    "\n",
    "# ### Discretize data ###\n",
    "# labels = [1,2,3]\n",
    "# PimaIndians[\"Pregnancies\"] = pd.qcut(PimaIndians[\"Pregnancies\"], len(labels), labels=labels)\n",
    "# PimaIndians[\"Glucose\"] = pd.qcut(PimaIndians[\"Glucose\"], len(labels), labels=labels)\n",
    "# PimaIndians[\"BloodPressure\"] = pd.qcut(PimaIndians[\"BloodPressure\"], len(labels), labels=labels)\n",
    "# PimaIndians[\"SkinThickness\"] = pd.qcut(PimaIndians[\"SkinThickness\"], len(labels), labels=labels)\n",
    "# PimaIndians[\"Insulin\"] = (PimaIndians[\"Insulin\"] == 0)\n",
    "# PimaIndians[\"Insulin\"] = PimaIndians[\"Insulin\"].astype(int)\n",
    "# PimaIndians[\"Insulin\"] = pd.Categorical(PimaIndians[\"Insulin\"])\n",
    "# PimaIndians[\"DiabetesPedigreeFunction\"] = pd.qcut(PimaIndians[\"DiabetesPedigreeFunction\"], len(labels), labels=labels)\n",
    "# PimaIndians[\"Age\"] = pd.qcut(PimaIndians[\"Age\"], len(labels), labels=labels)\n",
    "# PimaIndians[\"Y\"] = pd.Categorical(PimaIndians[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### One-hot encoding ###\n",
    "# categorical_columns = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"DiabetesPedigreeFunction\", \"Age\",]\n",
    "# encoder = OneHotEncoder(sparse_output=False, drop=None) \n",
    "# encoded = encoder.fit_transform(PimaIndians[categorical_columns])\n",
    "# encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "# encoded_df = pd.DataFrame(encoded, columns=encoded_columns)\n",
    "# PimaIndians_OneHot = pd.concat([encoded_df, PimaIndians[\"Y\"].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/simondn/Documents/RashomonActiveLearning/Data/processed/PimaIndians.pkl', 'wb') as file:\n",
    "#         pickle.dump(PimaIndians_OneHot, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "Finding Optimal Objective...\n",
      "treefarms reported successful execution\n",
      "training completed. Number of trees in the Rashomon set: 14\n",
      "{\n",
      "  \"false\": {\n",
      "    \"complexity\": 0.009999999776482582,\n",
      "    \"loss\": 0.1419270932674408,\n",
      "    \"name\": \"Y\",\n",
      "    \"prediction\": 0\n",
      "  },\n",
      "  \"feature\": 5,\n",
      "  \"model_objective\": 0.28171876072883606,\n",
      "  \"name\": \"Glucose_3\",\n",
      "  \"reference\": 1.0,\n",
      "  \"relation\": \"==\",\n",
      "  \"true\": {\n",
      "    \"complexity\": 0.009999999776482582,\n",
      "    \"loss\": 0.1197916716337204,\n",
      "    \"name\": \"Y\",\n",
      "    \"prediction\": 1\n",
      "  },\n",
      "  \"type\": \"rational\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<treeFarms.treefarms.model.treefarms.TREEFARMS at 0x11c2fba60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from treeFarms.treefarms.model.treefarms import TREEFARMS\n",
    "# TreeFarmsModel = TREEFARMS({\"regularization\": 0.01, \"rashomon_bound_multiplier\": 0.05})\n",
    "# TreeFarmsModel.fit(PimaIndians_OneHot.loc[:, PimaIndians_OneHot.columns != \"Y\"], PimaIndians_OneHot[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
