{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tutorial will exemplify the  Active Learning for Regression Using Greedy Sampling from Dongrui Wu, Chin-Teng Lin, Jian Huang.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Packages ###\n",
    "\n",
    "import os\n",
    "import math as math\n",
    "import pandas as pd\n",
    "import random as random\n",
    "\n",
    "### Append Path ###\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "### Local Packages ###\n",
    "from utils.Prediction import *\n",
    "from utils.Selector import *\n",
    "from utils.Auxiliary import *\n",
    "from utils.Main import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data ###\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
    "df = pd.DataFrame(data=boston.data, columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'])\n",
    "df = df.drop(columns=[\"CHAS\", \"RAD\"])\n",
    "df['Y'] = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Directory ###\n",
    "cwd = os.getcwd()\n",
    "ParentDirectory = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "\n",
    "### Input ###\n",
    "SimulationConfigInput = {'Seed': 1,                     # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'GSxFunction',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'RandomForestRegressorFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05,                          # Ignore this for now (used for Rashomon)\n",
    "    'Type': 'Regression'}                               # Options: [Classification, Regression]\n",
    "\n",
    "### Seed ###\n",
    "StartTime = time.time()\n",
    "random.seed(SimulationConfigInput[\"Seed\"])\n",
    "np.random.seed(SimulationConfigInput[\"Seed\"])\n",
    "\n",
    "### Store Results ###\n",
    "ErrorVec = []\n",
    "SelectedObservationHistory = []\n",
    "TreeCount = {\"AllTreeCount\": [], \"UniqueTreeCount\": []}\n",
    "\n",
    "### Train Test Candidate Split ###\n",
    "df_Train, df_Test, df_Candidate = TrainTestCandidateSplit(df, SimulationConfigInput[\"TestProportion\"], SimulationConfigInput[\"CandidateProportion\"])\n",
    "\n",
    "### Update SimulationConfig Arguments ###\n",
    "SimulationConfigInput['df_Train'] = df_Train\n",
    "SimulationConfigInput[\"df_Test\"] = df_Test\n",
    "SimulationConfigInput[\"df_Candidate\"] = df_Candidate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a loop that identifies parts of the active learning process. Look at each chunk and each section, and then go into the function in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Learning Procedure ###\n",
    "for i in range(len(df_Candidate)):\n",
    "\n",
    "    ### Prediction Model ###\n",
    "    print(\"Iteration: \" + str(i))\n",
    "    ModelType = globals().get(SimulationConfigInput[\"ModelType\"], None)                        # Extracts the right model\n",
    "    ModelArgsFiltered = FilterArguments(ModelType, SimulationConfigInput)                      # Selects the variables needed for the type of model\n",
    "    Model = ModelType(**ModelArgsFiltered)                                                     # Inputs the right variables needed for the type of model\n",
    "    SimulationConfigInput['Model'] = Model                                                     # Updates model\n",
    "\n",
    "    ### Test Error ###\n",
    "    TestErrorOutput = TestErrorFunction(InputModel = Model, df_Test = SimulationConfigInput[\"df_Test\"], Type = SimulationConfigInput[\"Type\"])\n",
    "    if('TREEFARMS' in str(type(Model))):                                                         # If Rashomon\n",
    "        CurrentError = TestErrorOutput[\"Error_Duplicate\"]\n",
    "    else: \n",
    "        CurrentError = TestErrorOutput[\"ErrorVal\"]                                               # One output for non-Rashomon\n",
    "    ErrorVec.append(CurrentError)\n",
    "\n",
    "    ### Sampling Procedure ###\n",
    "    SelectorType = globals().get(SimulationConfigInput[\"SelectorType\"], None)                      # Extracts the right selector\n",
    "    SelectorArgsFiltered = FilterArguments(SelectorType, SimulationConfigInput)                    # Selects the variables needed for the type of selector\n",
    "    SelectorFuncOutput = SelectorType(**SelectorArgsFiltered)                                      # Inputs the right variavles needed for the type of selector\n",
    "    QueryObservationIndex = SelectorFuncOutput[\"IndexRecommendation\"]                              # Extracts the index of the recommended observation\n",
    "    QueryObservation = SimulationConfigInput[\"df_Candidate\"].loc[[QueryObservationIndex]]          # Extracts the entire observation using the recommended index\n",
    "    SelectedObservationHistory.append(QueryObservationIndex)                                       # Appends to the selection history\n",
    "\n",
    "    ### Update Train and Candidate Sets ###\n",
    "    SimulationConfigInput[\"df_Train\"] = pd.concat([SimulationConfigInput[\"df_Train\"], QueryObservation])\n",
    "    SimulationConfigInput[\"df_Candidate\"] = SimulationConfigInput[\"df_Candidate\"].drop(QueryObservationIndex) \n",
    "\n",
    "    ### Store Number of (Unique) Trees ###\n",
    "    if('TREEFARMS' in str(type(Model))):\n",
    "        TreeCount[\"AllTreeCount\"].append(SelectorFuncOutput[\"AllTreeCount\"])          # Store number of trees\n",
    "        TreeCount[\"UniqueTreeCount\"].append(SelectorFuncOutput[\"UniqueTreeCount\"])    # Store number of unique/duplicate trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ErrorVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function OneIterationFunction will do all all of that above! The for loop was just written out so that you can see what is happenning internally and make the connection to the active learning procedure you've been reading in your papers. \n",
    "\n",
    "The only thing you have to change is the parameters in SimulationConfigInput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will run the active learning procedure with linear regression as the model. It will run the procedure with four different types of selectors: passive/random querying, GSx, GSy, and iGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegressionActiveLearningResults = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random/Passive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'PassiveLearning',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'RandomForestRegressorFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "LinearRegressionResults_Passive = OneIterationFunction(SimulationConfigInput)\n",
    "LinearRegressionActiveLearningResults[\"Passive\"] = LinearRegressionResults_Passive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector: GSx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'GSxFunction',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'LinearRegressionFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "LinearRegressionResults_GSx = OneIterationFunction(SimulationConfigInput)\n",
    "LinearRegressionActiveLearningResults[\"GSx\"] = LinearRegressionResults_GSx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector: GSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'GSyFunction',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'LinearRegressionFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "LinearRegressionResults_GSy = OneIterationFunction(SimulationConfigInput)\n",
    "LinearRegressionActiveLearningResults[\"GSy\"] = LinearRegressionResults_GSy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector: iGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'iGSFunction',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'LinearRegressionFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "LinearRegressionResults_iGS = OneIterationFunction(SimulationConfigInput)\n",
    "LinearRegressionActiveLearningResults[\"iGS\"] = LinearRegressionResults_iGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Active Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Up ###\n",
    "SimulationErrorResults = {\"Passive\" : LinearRegressionActiveLearningResults[\"Passive\"][\"ErrorVec\"],\n",
    "                          \"GSx\" : LinearRegressionActiveLearningResults[\"GSx\"][\"ErrorVec\"],\n",
    "                          \"GSy\" : LinearRegressionActiveLearningResults[\"GSy\"][\"ErrorVec\"],\n",
    "                          \"iGS\" : LinearRegressionActiveLearningResults[\"iGS\"][\"ErrorVec\"],}\n",
    "\n",
    "### Aesthetics ###\n",
    "# PlotSubtitle = f\"Dataset: {SimulationConfigInput[\"DataFileInput\"]}\"\n",
    "PlotSubtitle=\"BostonHousing with Linear Regression\"\n",
    "Colors = {\n",
    "    \"Passive\": \"black\",\n",
    "    \"GSx\": \"green\",\n",
    "    \"GSy\": \"orange\",\n",
    "    \"iGS\": \"blue\"\n",
    "}\n",
    "\n",
    "Linestyles = {\n",
    "    \"Passive\": \"solid\",\n",
    "    \"GSx\": \"solid\",\n",
    "    \"GSy\": \"solid\",\n",
    "    \"iGS\": \"solid\"\n",
    "}\n",
    "\n",
    "LegendMapping = {\n",
    "    \"Passive\": \"Passive\",\n",
    "    \"GSx\": \"GSx\",\n",
    "    \"GSy\": \"GSy\",\n",
    "    \"iGS\": \"iGS\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mean Plot ###\n",
    "plt.figure(figsize=[10,5])\n",
    "for Label, Values in SimulationErrorResults.items():\n",
    "    x = 20 + (np.arange(len(Values)) / len(Values)) * 80  # Start at 20% and go to 100%\n",
    "    color = Colors.get(Label, None) if Colors else None \n",
    "    linestyle = Linestyles.get(Label, ':') if Linestyles else ':'\n",
    "    legend_label = LegendMapping[Label] if LegendMapping and Label in LegendMapping else Label\n",
    "    plt.plot(x, Values, label=legend_label, color=color, linestyle=linestyle)\n",
    "\n",
    "plt.suptitle(\"Active Learning Mean Error Plot\")\n",
    "plt.xlabel(\"Percent of labelled observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(PlotSubtitle, fontsize=9)\n",
    "plt.legend(loc='upper right')\n",
    "MeanPlot = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will run the active learning procedure with linear regression as the model. It will run the procedure with four different types of selectors: passive/random querying, GSx, GSy, and iGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestsActiveLearningResults = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random/Passive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'PassiveLearning',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'RandomForestRegressorFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "RandomForestsResults_Passive = OneIterationFunction(SimulationConfigInput)\n",
    "RandomForestsActiveLearningResults[\"Passive\"] = RandomForestsResults_Passive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector: GSx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'GSxFunction',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'RandomForestRegressorFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "RandomForestsResults_GSx = OneIterationFunction(SimulationConfigInput)\n",
    "RandomForestsActiveLearningResults[\"GSx\"] = RandomForestsResults_GSx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector: GSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'GSyFunction',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'RandomForestRegressorFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "RandomForestsResults_GSy = OneIterationFunction(SimulationConfigInput)\n",
    "RandomForestsActiveLearningResults[\"GSy\"] = RandomForestsResults_GSy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector: iGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input ###\n",
    "SimulationConfigInput = {\n",
    "    \"DataFileInput\" : \"BostonHousing\",                  # Data File Input\n",
    "    'Seed': 1,                                          # Seed\n",
    "    'TestProportion': 0.2,                              # Test proportion\n",
    "    'CandidateProportion': 0.8,                         # Candidate proportion\n",
    "    'SelectorType': 'iGSFunction',                      # Options: [GSxFunction, GSyFunction, iGSFunction, PassiveLearning] (all of these are for regression)\n",
    "    'ModelType': 'RandomForestRegressorFunction',       # Options: [LinearRegressionFunction, RandomForestRegressorFunction] (all of these are for regression)\n",
    "    'n_estimators': 100,                                # If using RandomForestRegressorFunction/RandomForestClassificationFunction, this is the number of trees\n",
    "    'Type': 'Regression',                               # Options: [Classification, Regression]\n",
    "    'UniqueErrorsInput': 0,                             # Ignore this for now (used for Rashomon)\n",
    "    'regularization': 0.01,                             # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThresholdType': \"Adder\",                   # Ignore this for now (used for Rashomon)\n",
    "    'RashomonThreshold': 0.05}                          # Ignore this for now (used for Rashomon)\n",
    "\n",
    "### Run Function\n",
    "RandomForestsResults_iGS = OneIterationFunction(SimulationConfigInput)\n",
    "RandomForestsActiveLearningResults[\"iGS\"] = RandomForestsResults_iGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Active Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Up ###\n",
    "SimulationErrorResults = {\"Passive\" : RandomForestsActiveLearningResults[\"Passive\"][\"ErrorVec\"],\n",
    "                          \"GSx\" : RandomForestsActiveLearningResults[\"GSx\"][\"ErrorVec\"],\n",
    "                          \"GSy\" : RandomForestsActiveLearningResults[\"GSy\"][\"ErrorVec\"],\n",
    "                          \"iGS\" : RandomForestsActiveLearningResults[\"iGS\"][\"ErrorVec\"],}\n",
    "\n",
    "### Aesthetics ###\n",
    "# PlotSubtitle = f\"Dataset: {SimulationConfigInput[\"DataFileInput\"]}\"\n",
    "PlotSubtitle= \"BostonHousing with RandomForests\"\n",
    "Colors = {\n",
    "    \"Passive\": \"black\",\n",
    "    \"GSx\": \"green\",\n",
    "    \"GSy\": \"orange\",\n",
    "    \"iGS\": \"blue\"\n",
    "}\n",
    "\n",
    "Linestyles = {\n",
    "    \"Passive\": \"solid\",\n",
    "    \"GSx\": \"solid\",\n",
    "    \"GSy\": \"solid\",\n",
    "    \"iGS\": \"solid\"\n",
    "}\n",
    "\n",
    "LegendMapping = {\n",
    "    \"Passive\": \"Passive\",\n",
    "    \"GSx\": \"GSx\",\n",
    "    \"GSy\": \"GSy\",\n",
    "    \"iGS\": \"iGS\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mean Plot ###\n",
    "plt.figure(figsize=[10,5])\n",
    "for Label, Values in SimulationErrorResults.items():\n",
    "    x = 20 + (np.arange(len(Values)) / len(Values)) * 80  # Start at 20% and go to 100%\n",
    "    color = Colors.get(Label, None) if Colors else None \n",
    "    linestyle = Linestyles.get(Label, ':') if Linestyles else ':'\n",
    "    legend_label = LegendMapping[Label] if LegendMapping and Label in LegendMapping else Label\n",
    "    plt.plot(x, Values, label=legend_label, color=color, linestyle=linestyle)\n",
    "\n",
    "plt.suptitle(\"Active Learning Mean Error Plot\")\n",
    "plt.xlabel(\"Percent of labelled observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(PlotSubtitle, fontsize=9)\n",
    "plt.legend(loc='upper right')\n",
    "MeanPlot = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiple Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinadily, in order to compare methods we want a wide range of simulations. In the above work, we only ran 1 simulation. Instead, we want to run 100 simulations each with diferent seeds for eah method, average the methods, then compare their results. I will walk you through this. \n",
    "\n",
    "1. Firstly, initialize a list for the four selector methods methods (one for each mehod: GSxFunction, GSyFunction, iGSFunction, PassiveLearning) to store your results.\n",
    "2. Within a for loop between 0 and 99, \n",
    "    - Set the seed to the current number of the looop\n",
    "    - Construct 4 SimulationConfigInput\n",
    "    - Run the four iteration functions for each method.\n",
    "        - OneIterationFunction(SimulationConfigInput_Passive)\n",
    "        - OneIterationFunction(SimulationConfigInput_GSx)\n",
    "        - OneIterationFunction(SimulationConfigInput_GSy)\n",
    "        - OneIterationFunction(SimulationConfigInput_iGS)\n",
    "    - Append each of the four methods to their respective results.\n",
    "3. Average the error results within the four methods.\n",
    "4. Create an active learning plot showing the time by number of labelled observations.\n",
    "5. Report the average run time of each selector method.\n",
    "\n",
    "Note this will take **a very long time!** I suspect each loop to take 2 minutes. You are essentially running 4 active learning processes 100 times (with each active learning process takeung about 30 seconds). I would recommend letting this run overnight. Next week, I will show you how can you run this on the university High-Performance Computing Cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store simulation results for each selector method.\n",
    "results_passive = []\n",
    "results_GSx = []\n",
    "results_GSy = []\n",
    "results_iGS = []\n",
    "\n",
    "# Run 100 simulations.\n",
    "n_simulations = 100\n",
    "\n",
    "for seed in range(n_simulations):\n",
    "    # Base configuration shared across methods.\n",
    "    base_config = {\n",
    "        \"DataFileInput\": \"BostonHousing\",\n",
    "        \"Seed\": seed,\n",
    "        \"TestProportion\": 0.2,\n",
    "        \"CandidateProportion\": 0.8,\n",
    "        \"ModelType\": \"LinearRegressionFunction\",  # or \"RandomForestRegressorFunction\" if desired\n",
    "        \"n_estimators\": 100,\n",
    "        \"Type\": \"Regression\",\n",
    "        \"UniqueErrorsInput\": 0,\n",
    "        \"regularization\": 0.01,\n",
    "        \"RashomonThresholdType\": \"Adder\",\n",
    "        \"RashomonThreshold\": 0.05,\n",
    "    }\n",
    "    \n",
    "    # Create separate configuration dictionaries for each selector.\n",
    "    config_passive = base_config.copy()\n",
    "    config_passive[\"SelectorType\"] = \"PassiveLearning\"\n",
    "    \n",
    "    config_GSx = base_config.copy()\n",
    "    config_GSx[\"SelectorType\"] = \"GSxFunction\"\n",
    "    \n",
    "    config_GSy = base_config.copy()\n",
    "    config_GSy[\"SelectorType\"] = \"GSyFunction\"\n",
    "    \n",
    "    config_iGS = base_config.copy()\n",
    "    config_iGS[\"SelectorType\"] = \"iGSFunction\"\n",
    "    \n",
    "    # Run the one-iteration active learning process for each configuration.\n",
    "    result_passive = OneIterationFunction(config_passive)\n",
    "    result_GSx = OneIterationFunction(config_GSx)\n",
    "    result_GSy = OneIterationFunction(config_GSy)\n",
    "    result_iGS = OneIterationFunction(config_iGS)\n",
    "    \n",
    "    # Append the results.\n",
    "    results_passive.append(result_passive)\n",
    "    results_GSx.append(result_GSx)\n",
    "    results_GSy.append(result_GSy)\n",
    "    results_iGS.append(result_iGS)\n",
    "\n",
    "# Helper function to average the error curves.\n",
    "def average_error(results):\n",
    "    # Each result's \"ErrorVec\" is assumed to be a DataFrame with a column \"Error\".\n",
    "    error_arrays = [result[\"ErrorVec\"][\"Error\"].values for result in results]\n",
    "    error_arrays = np.array(error_arrays)\n",
    "    return np.mean(error_arrays, axis=0)\n",
    "\n",
    "# Calculate the average error for each selector method.\n",
    "avg_error_passive = average_error(results_passive)\n",
    "avg_error_GSx = average_error(results_GSx)\n",
    "avg_error_GSy = average_error(results_GSy)\n",
    "avg_error_iGS = average_error(results_iGS)\n",
    "\n",
    "# Helper function to average the runtime.\n",
    "def average_runtime(results):\n",
    "    runtimes = [result[\"ElapsedTime\"] for result in results]\n",
    "    return np.mean(runtimes)\n",
    "\n",
    "# Calculate the average runtime for each method.\n",
    "avg_time_passive = average_runtime(results_passive)\n",
    "avg_time_GSx = average_runtime(results_GSx)\n",
    "avg_time_GSy = average_runtime(results_GSy)\n",
    "avg_time_iGS = average_runtime(results_iGS)\n",
    "\n",
    "print(\"Average runtime (seconds):\")\n",
    "print(\"Passive:\", avg_time_passive)\n",
    "print(\"GSx:\", avg_time_GSx)\n",
    "print(\"GSy:\", avg_time_GSy)\n",
    "print(\"iGS:\", avg_time_iGS)\n",
    "\n",
    "# Plot the average error curves.\n",
    "# Here we assume that the x-axis represents the percentage of labelled observations,\n",
    "# starting at 20% (TestProportion) and ending at 100%.\n",
    "num_iterations = len(avg_error_passive)\n",
    "x_values = np.linspace(20, 100, num_iterations)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_values, avg_error_passive, label=\"Passive\", color=\"black\")\n",
    "plt.plot(x_values, avg_error_GSx, label=\"GSx\", color=\"green\")\n",
    "plt.plot(x_values, avg_error_GSy, label=\"GSy\", color=\"orange\")\n",
    "plt.plot(x_values, avg_error_iGS, label=\"iGS\", color=\"blue\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Active Learning Mean Error Plot\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to change things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add your own selector techinque or model technique, go to the respective directory (~/utils.Prediction for prediction models or ~/utils.Selector for the selection method) and add your own function! Then in SimulationConfigInput, change the SelectorType or ModelType input to the names of your functions. Try adding a new function (for instance, maybe a support vector machine) to the methods section and try running it!\n",
    "\n",
    "Additionally, you (Troy) had good ideas for a new selector method. Try to see if you can implement it. Make sure the output is the same as the models/selector methods listed there.\n",
    "\n",
    "Run the code below to see if it's working, and compare the results to what we've had."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Iteration of everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base configuration shared across methods. \n",
    "base_config = {\n",
    "    \"DataFileInput\": \"BostonHousing\",\n",
    "    \"Seed\": 1,\n",
    "    \"TestProportion\": 0.2,\n",
    "    \"CandidateProportion\": 0.8,\n",
    "    \"ModelType\": \"LinearRegressionFunction\",  # or \"RandomForestRegressorFunction\" if desired\n",
    "    \"n_estimators\": 100,\n",
    "    \"Type\": \"Regression\",\n",
    "    \"UniqueErrorsInput\": 0,\n",
    "    \"regularization\": 0.01,\n",
    "    \"RashomonThresholdType\": \"Adder\",\n",
    "    \"RashomonThreshold\": 0.05,\n",
    "}\n",
    "\n",
    "# Create separate configuration dictionaries for each selector.\n",
    "config_passive    = base_config.copy(); config_passive[\"SelectorType\"]    = \"PassiveLearning\"\n",
    "config_GSx        = base_config.copy(); config_GSx[\"SelectorType\"]        = \"GSxFunction\"              # original GSx (min distance)\n",
    "config_GSxAvg     = base_config.copy(); config_GSxAvg[\"SelectorType\"]     = \"GSxFunctionAverage\"       # average GSx\n",
    "config_GSy        = base_config.copy(); config_GSy[\"SelectorType\"]        = \"GSyFunction\"              # original GSy (min distance)\n",
    "config_GSyAvg     = base_config.copy(); config_GSyAvg[\"SelectorType\"]     = \"GSyFunctionAverage\"       # average GSy\n",
    "config_iGS        = base_config.copy(); config_iGS[\"SelectorType\"]        = \"iGSFunction\"              # original iGS (min distances multiplied)\n",
    "config_iGSAvg     = base_config.copy(); config_iGSAvg[\"SelectorType\"]     = \"iGSFunctionAverage\"       # average iGS (multiplication)\n",
    "config_iGSStd     = base_config.copy(); config_iGSStd[\"SelectorType\"]     = \"iGSFunctionStandardized\"  # standardized iGS (min distances)\n",
    "config_iGSAvgStd  = base_config.copy(); config_iGSAvgStd[\"SelectorType\"]  = \"iGSFunctionAverageStandardized\"  # standardized iGS (average distances)\n",
    "\n",
    "# =============================================================================\n",
    "# Run the one-iteration active learning process for each configuration.\n",
    "# (Note: OneIterationFunction must be defined elsewhere in your project)\n",
    "\n",
    "result_passive   = OneIterationFunction(config_passive)\n",
    "result_GSx       = OneIterationFunction(config_GSx)\n",
    "result_GSxAvg    = OneIterationFunction(config_GSxAvg)\n",
    "result_GSy       = OneIterationFunction(config_GSy)\n",
    "result_GSyAvg    = OneIterationFunction(config_GSyAvg)\n",
    "result_iGS       = OneIterationFunction(config_iGS)\n",
    "result_iGSAvg    = OneIterationFunction(config_iGSAvg)\n",
    "result_iGSStd    = OneIterationFunction(config_iGSStd)\n",
    "result_iGSAvgStd = OneIterationFunction(config_iGSAvgStd)\n",
    "\n",
    "# Append the results to corresponding lists.\n",
    "results_passive   = []\n",
    "results_GSx       = []\n",
    "results_GSxAvg    = []\n",
    "results_GSy       = []\n",
    "results_GSyAvg    = []\n",
    "results_iGS       = []\n",
    "results_iGSAvg    = []\n",
    "results_iGSStd    = []\n",
    "results_iGSAvgStd = []\n",
    "\n",
    "results_passive.append(result_passive)\n",
    "results_GSx.append(result_GSx)\n",
    "results_GSxAvg.append(result_GSxAvg)\n",
    "results_GSy.append(result_GSy)\n",
    "results_GSyAvg.append(result_GSyAvg)\n",
    "results_iGS.append(result_iGS)\n",
    "results_iGSAvg.append(result_iGSAvg)\n",
    "results_iGSStd.append(result_iGSStd)\n",
    "results_iGSAvgStd.append(result_iGSAvgStd)\n",
    "\n",
    "# =============================================================================\n",
    "# Helper function to compute the average error.\n",
    "def average_error(results):\n",
    "    # Each result's \"ErrorVec\" is assumed to be a DataFrame with a column \"Error\".\n",
    "    error_arrays = [result[\"ErrorVec\"][\"Error\"].values for result in results]\n",
    "    error_arrays = np.array(error_arrays)\n",
    "    return np.mean(error_arrays, axis=0)\n",
    "\n",
    "# Calculate the average error for each selector method.\n",
    "avg_error_passive   = average_error(results_passive)\n",
    "avg_error_GSx       = average_error(results_GSx)\n",
    "avg_error_GSxAvg    = average_error(results_GSxAvg)\n",
    "avg_error_GSy       = average_error(results_GSy)\n",
    "avg_error_GSyAvg    = average_error(results_GSyAvg)\n",
    "avg_error_iGS       = average_error(results_iGS)\n",
    "avg_error_iGSAvg    = average_error(results_iGSAvg)\n",
    "avg_error_iGSStd    = average_error(results_iGSStd)\n",
    "avg_error_iGSAvgStd = average_error(results_iGSAvgStd)\n",
    "\n",
    "# =============================================================================\n",
    "# Helper function to average the runtime.\n",
    "def average_runtime(results):\n",
    "    runtimes = [result[\"ElapsedTime\"] for result in results]\n",
    "    return np.mean(runtimes)\n",
    "\n",
    "# Calculate the average runtime for each method.\n",
    "avg_time_passive   = average_runtime(results_passive)\n",
    "avg_time_GSx       = average_runtime(results_GSx)\n",
    "avg_time_GSxAvg    = average_runtime(results_GSxAvg)\n",
    "avg_time_GSy       = average_runtime(results_GSy)\n",
    "avg_time_GSyAvg    = average_runtime(results_GSyAvg)\n",
    "avg_time_iGS       = average_runtime(results_iGS)\n",
    "avg_time_iGSAvg    = average_runtime(results_iGSAvg)\n",
    "avg_time_iGSStd    = average_runtime(results_iGSStd)\n",
    "avg_time_iGSAvgStd = average_runtime(results_iGSAvgStd)\n",
    "\n",
    "print(\"Average runtime (seconds):\")\n",
    "print(\"Passive:                \", avg_time_passive)\n",
    "print(\"GSx (original):         \", avg_time_GSx)\n",
    "print(\"GSx (average):          \", avg_time_GSxAvg)\n",
    "print(\"GSy (original):         \", avg_time_GSy)\n",
    "print(\"GSy (average):          \", avg_time_GSyAvg)\n",
    "print(\"iGS (original):         \", avg_time_iGS)\n",
    "print(\"iGS (average):          \", avg_time_iGSAvg)\n",
    "print(\"iGS (standardized min): \", avg_time_iGSStd)\n",
    "print(\"iGS (average standardized):\", avg_time_iGSAvgStd)\n",
    "\n",
    "# =============================================================================\n",
    "# Plot the average error curves.\n",
    "# We assume the x-axis represents the percentage of labelled observations,\n",
    "# starting at 20% (TestProportion) and ending at 100%.\n",
    "num_iterations = len(avg_error_passive)\n",
    "x_values = np.linspace(20, 100, num_iterations)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_values, avg_error_passive,   label=\"Passive\",                 color=\"black\")\n",
    "plt.plot(x_values, avg_error_GSx,       label=\"GSx (original)\",          color=\"green\")\n",
    "plt.plot(x_values, avg_error_GSxAvg,    label=\"GSx (average)\",           color=\"lime\")\n",
    "plt.plot(x_values, avg_error_GSy,       label=\"GSy (original)\",          color=\"orange\")\n",
    "plt.plot(x_values, avg_error_GSyAvg,    label=\"GSy (average)\",           color=\"gold\")\n",
    "plt.plot(x_values, avg_error_iGS,       label=\"iGS (original)\",          color=\"blue\")\n",
    "plt.plot(x_values, avg_error_iGSAvg,    label=\"iGS (average)\",           color=\"cyan\")\n",
    "plt.plot(x_values, avg_error_iGSStd,    label=\"iGS (standardized min)\",  color=\"red\")\n",
    "plt.plot(x_values, avg_error_iGSAvgStd, label=\"iGS (average standardized)\", color=\"purple\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Active Learning Mean Error Plot\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot for GSx (original vs average)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_GSx, label=\"GSx (original)\", color=\"green\")\n",
    "plt.plot(x_values, avg_error_GSxAvg, label=\"GSx (average)\", color=\"lime\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"GSx vs GSx (average)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for GSy (original vs average)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_GSy, label=\"GSy (original)\", color=\"orange\")\n",
    "plt.plot(x_values, avg_error_GSyAvg, label=\"GSy (average)\", color=\"gold\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"GSy vs GSy (average)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for iGS (original vs average)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_iGS, label=\"iGS (original)\", color=\"blue\")\n",
    "plt.plot(x_values, avg_error_iGSAvg, label=\"iGS (average)\", color=\"cyan\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"iGS vs iGS (average)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for iGS variants (original vs standardized min vs average standardized)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_iGS, label=\"iGS (original)\", color=\"blue\")\n",
    "plt.plot(x_values, avg_error_iGSStd, label=\"iGS (standardized min)\", color=\"red\")\n",
    "plt.plot(x_values, avg_error_iGSAvgStd, label=\"iGS (average standardized)\", color=\"purple\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"iGS vs Standardized Variants\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store simulation results for each selector method.\n",
    "results_passive   = []\n",
    "results_GSx       = []\n",
    "results_GSxAvg    = []\n",
    "results_GSy       = []\n",
    "results_GSyAvg    = []\n",
    "results_iGS       = []\n",
    "results_iGSAvg    = []\n",
    "results_iGSStd    = []\n",
    "results_iGSAvgStd = []\n",
    "\n",
    "# Run 100 simulations.\n",
    "n_simulations = 100\n",
    "\n",
    "for seed in range(n_simulations):\n",
    "    # Base configuration shared across methods. \n",
    "    base_config = {\n",
    "        \"DataFileInput\": \"BostonHousing\",\n",
    "        \"Seed\": seed,\n",
    "        \"TestProportion\": 0.2,\n",
    "        \"CandidateProportion\": 0.8,\n",
    "        \"ModelType\": \"LinearRegressionFunction\",  # or \"RandomForestRegressorFunction\" if desired\n",
    "        \"n_estimators\": 100,\n",
    "        \"Type\": \"Regression\",\n",
    "        \"UniqueErrorsInput\": 0,\n",
    "        \"regularization\": 0.01,\n",
    "        \"RashomonThresholdType\": \"Adder\",\n",
    "        \"RashomonThreshold\": 0.05,\n",
    "    }\n",
    "\n",
    "    # Create separate configuration dictionaries for each selector.\n",
    "    config_passive    = base_config.copy(); config_passive[\"SelectorType\"]    = \"PassiveLearning\"\n",
    "    config_GSx        = base_config.copy(); config_GSx[\"SelectorType\"]        = \"GSxFunction\"              # original GSx (min distance)\n",
    "    config_GSxAvg     = base_config.copy(); config_GSxAvg[\"SelectorType\"]     = \"GSxFunctionAverage\"       # average GSx\n",
    "    config_GSy        = base_config.copy(); config_GSy[\"SelectorType\"]        = \"GSyFunction\"              # original GSy (min distance)\n",
    "    config_GSyAvg     = base_config.copy(); config_GSyAvg[\"SelectorType\"]     = \"GSyFunctionAverage\"       # average GSy\n",
    "    config_iGS        = base_config.copy(); config_iGS[\"SelectorType\"]        = \"iGSFunction\"              # original iGS (min distances multiplied)\n",
    "    config_iGSAvg     = base_config.copy(); config_iGSAvg[\"SelectorType\"]     = \"iGSFunctionAverage\"       # average iGS (multiplication)\n",
    "    config_iGSStd     = base_config.copy(); config_iGSStd[\"SelectorType\"]     = \"iGSFunctionStandardized\"  # standardized iGS (min distances)\n",
    "    config_iGSAvgStd  = base_config.copy(); config_iGSAvgStd[\"SelectorType\"]  = \"iGSFunctionAverageStandardized\"  # standardized iGS (average distances)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Run the one-iteration active learning process for each configuration.\n",
    "    # (Note: OneIterationFunction must be defined elsewhere in your project)\n",
    "\n",
    "    result_passive   = OneIterationFunction(config_passive)\n",
    "    result_GSx       = OneIterationFunction(config_GSx)\n",
    "    result_GSxAvg    = OneIterationFunction(config_GSxAvg)\n",
    "    result_GSy       = OneIterationFunction(config_GSy)\n",
    "    result_GSyAvg    = OneIterationFunction(config_GSyAvg)\n",
    "    result_iGS       = OneIterationFunction(config_iGS)\n",
    "    result_iGSAvg    = OneIterationFunction(config_iGSAvg)\n",
    "    result_iGSStd    = OneIterationFunction(config_iGSStd)\n",
    "    result_iGSAvgStd = OneIterationFunction(config_iGSAvgStd)\n",
    "\n",
    "    results_passive.append(result_passive)\n",
    "    results_GSx.append(result_GSx)\n",
    "    results_GSxAvg.append(result_GSxAvg)\n",
    "    results_GSy.append(result_GSy)\n",
    "    results_GSyAvg.append(result_GSyAvg)\n",
    "    results_iGS.append(result_iGS)\n",
    "    results_iGSAvg.append(result_iGSAvg)\n",
    "    results_iGSStd.append(result_iGSStd)\n",
    "    results_iGSAvgStd.append(result_iGSAvgStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Helper function to compute the average error.\n",
    "def average_error(results):\n",
    "    # Each result's \"ErrorVec\" is assumed to be a DataFrame with a column \"Error\".\n",
    "    error_arrays = [result[\"ErrorVec\"][\"Error\"].values for result in results]\n",
    "    error_arrays = np.array(error_arrays)\n",
    "    return np.mean(error_arrays, axis=0)\n",
    "\n",
    "# Calculate the average error for each selector method.\n",
    "avg_error_passive   = average_error(results_passive)\n",
    "avg_error_GSx       = average_error(results_GSx)\n",
    "avg_error_GSxAvg    = average_error(results_GSxAvg)\n",
    "avg_error_GSy       = average_error(results_GSy)\n",
    "avg_error_GSyAvg    = average_error(results_GSyAvg)\n",
    "avg_error_iGS       = average_error(results_iGS)\n",
    "avg_error_iGSAvg    = average_error(results_iGSAvg)\n",
    "avg_error_iGSStd    = average_error(results_iGSStd)\n",
    "avg_error_iGSAvgStd = average_error(results_iGSAvgStd)\n",
    "\n",
    "# =============================================================================\n",
    "# Helper function to average the runtime.\n",
    "def average_runtime(results):\n",
    "    runtimes = [result[\"ElapsedTime\"] for result in results]\n",
    "    return np.mean(runtimes)\n",
    "\n",
    "# Calculate the average runtime for each method.\n",
    "avg_time_passive   = average_runtime(results_passive)\n",
    "avg_time_GSx       = average_runtime(results_GSx)\n",
    "avg_time_GSxAvg    = average_runtime(results_GSxAvg)\n",
    "avg_time_GSy       = average_runtime(results_GSy)\n",
    "avg_time_GSyAvg    = average_runtime(results_GSyAvg)\n",
    "avg_time_iGS       = average_runtime(results_iGS)\n",
    "avg_time_iGSAvg    = average_runtime(results_iGSAvg)\n",
    "avg_time_iGSStd    = average_runtime(results_iGSStd)\n",
    "avg_time_iGSAvgStd = average_runtime(results_iGSAvgStd)\n",
    "\n",
    "print(\"Average runtime (seconds):\")\n",
    "print(\"Passive:                \", avg_time_passive)\n",
    "print(\"GSx (original):         \", avg_time_GSx)\n",
    "print(\"GSx (average):          \", avg_time_GSxAvg)\n",
    "print(\"GSy (original):         \", avg_time_GSy)\n",
    "print(\"GSy (average):          \", avg_time_GSyAvg)\n",
    "print(\"iGS (original):         \", avg_time_iGS)\n",
    "print(\"iGS (average):          \", avg_time_iGSAvg)\n",
    "print(\"iGS (standardized min): \", avg_time_iGSStd)\n",
    "print(\"iGS (average standardized):\", avg_time_iGSAvgStd)\n",
    "\n",
    "# =============================================================================\n",
    "# Plot the average error curves.\n",
    "# We assume the x-axis represents the percentage of labelled observations,\n",
    "# starting at 20% (TestProportion) and ending at 100%.\n",
    "num_iterations = len(avg_error_passive)\n",
    "x_values = np.linspace(20, 100, num_iterations)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_values, avg_error_passive,   label=\"Passive\",                 color=\"black\")\n",
    "plt.plot(x_values, avg_error_GSx,       label=\"GSx (original)\",          color=\"green\")\n",
    "plt.plot(x_values, avg_error_GSxAvg,    label=\"GSx (average)\",           color=\"lime\")\n",
    "plt.plot(x_values, avg_error_GSy,       label=\"GSy (original)\",          color=\"orange\")\n",
    "plt.plot(x_values, avg_error_GSyAvg,    label=\"GSy (average)\",           color=\"gold\")\n",
    "plt.plot(x_values, avg_error_iGS,       label=\"iGS (original)\",          color=\"blue\")\n",
    "plt.plot(x_values, avg_error_iGSAvg,    label=\"iGS (average)\",           color=\"cyan\")\n",
    "plt.plot(x_values, avg_error_iGSStd,    label=\"iGS (standardized min)\",  color=\"red\")\n",
    "plt.plot(x_values, avg_error_iGSAvgStd, label=\"iGS (average standardized)\", color=\"purple\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Active Learning Mean Error Plot\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot for GSx (original vs average)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_GSx, label=\"GSx (original)\", color=\"green\")\n",
    "plt.plot(x_values, avg_error_GSxAvg, label=\"GSx (average)\", color=\"lime\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"GSx vs GSx (average)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for GSy (original vs average)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_GSy, label=\"GSy (original)\", color=\"orange\")\n",
    "plt.plot(x_values, avg_error_GSyAvg, label=\"GSy (average)\", color=\"gold\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"GSy vs GSy (average)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for iGS (original vs average)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_iGS, label=\"iGS (original)\", color=\"blue\")\n",
    "plt.plot(x_values, avg_error_iGSAvg, label=\"iGS (average)\", color=\"cyan\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"iGS vs iGS (average)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for iGS variants (original vs standardized min vs average standardized)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_iGS, label=\"iGS (original)\", color=\"blue\")\n",
    "plt.plot(x_values, avg_error_iGSStd, label=\"iGS (standardized min)\", color=\"red\")\n",
    "plt.plot(x_values, avg_error_iGSAvgStd, label=\"iGS (average standardized)\", color=\"purple\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"iGS vs Standardized Variants\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for iGS variants (original vs standardized min vs average standardized)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_values, avg_error_iGSAvg, label=\"iGS (original)\", color=\"cyan\")\n",
    "plt.plot(x_values, avg_error_iGSStd, label=\"iGS (standardized min)\", color=\"red\")\n",
    "plt.plot(x_values, avg_error_iGSAvgStd, label=\"iGS (average standardized)\", color=\"purple\")\n",
    "plt.xlabel(\"Percent of Labelled Observations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"iGSAvg vs Standardized Variants\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Assuming that result_passive, result_GSx, etc. are dictionaries returned from OneIterationFunction\n",
    "SimulationErrorResults = {\n",
    "    'passive': np.array(result_passive[\"ErrorVec\"][\"Error\"].values),\n",
    "    'GSx': np.array(result_GSx[\"ErrorVec\"][\"Error\"].values),\n",
    "    'GSxAvg': np.array(result_GSxAvg[\"ErrorVec\"][\"Error\"].values),\n",
    "    'GSy': np.array(result_GSy[\"ErrorVec\"][\"Error\"].values),\n",
    "    'GSyAvg': np.array(result_GSyAvg[\"ErrorVec\"][\"Error\"].values),\n",
    "    'iGS': np.array(result_iGS[\"ErrorVec\"][\"Error\"].values),\n",
    "    'iGSAvg': np.array(result_iGSAvg[\"ErrorVec\"][\"Error\"].values),\n",
    "    'iGSStd': np.array(result_iGSStd[\"ErrorVec\"][\"Error\"].values),\n",
    "    'iGSAvgStd': np.array(result_iGSAvgStd[\"ErrorVec\"][\"Error\"].values)\n",
    "}\n",
    "\n",
    "wilcox_results = WilcoxonRankSignedTest(SimulationErrorResults)\n",
    "print(wilcox_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDING MORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes, fetch_california_housing, fetch_openml\n",
    "import pandas as pd\n",
    "### Import Packages ###\n",
    "\n",
    "import os\n",
    "import math as math\n",
    "import pandas as pd\n",
    "import random as random\n",
    "\n",
    "### Append Path ###\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "### Local Packages ###\n",
    "from utils.Prediction import *\n",
    "from utils.Selector import *\n",
    "from utils.Auxiliary import *\n",
    "from utils.Main import *\n",
    "\n",
    "# 1. Diabetes Dataset (Regression)\n",
    "diabetes = load_diabetes()\n",
    "df_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "df_diabetes['target'] = diabetes.target\n",
    "\n",
    "# 2. California Housing Dataset (Regression)\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "df_california = california.frame  # Already a DataFrame, target in 'MedHouseVal'\n",
    "df_california.rename(columns={\"MedHouseVal\": \"target\"}, inplace=True)\n",
    "\n",
    "# 3. Boston Housing Dataset (Regression)\n",
    "# Note: Boston Housing is deprecated for ethical reasons.\n",
    "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
    "df_boston = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df_boston['target'] = boston.target\n",
    "\n",
    "# 4. Ames Housing Dataset (Regression)\n",
    "# Use the dataset ID to avoid URL issues with spaces in the name.\n",
    "ames = fetch_openml(data_id=42165, as_frame=True)\n",
    "df_ames = pd.DataFrame(ames.data)\n",
    "df_ames['target'] = ames.target\n",
    "\n",
    "\n",
    "# Combine into a dictionary of datasets\n",
    "datasets = {\n",
    "    \"Diabetes\": df_diabetes,\n",
    "    \"CaliforniaHousing\": df_california,\n",
    "    \"BostonHousing\": df_boston,\n",
    "    \"AmesHousing\": df_ames,\n",
    "}\n",
    "\n",
    "# Inspect one of the datasets (e.g., Ames Housing)\n",
    "#print(datasets[\"Concrete\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Diabetes\": df_diabetes,\n",
    "    # \"CaliforniaHousing\": df_california,\n",
    "    # \"BostonHousing\": df_boston,\n",
    "    # \"AmesHousing\": df_ames,\n",
    "}\n",
    "\n",
    "def drop_non_numeric_columns(df, label_col=\"Y\"):\n",
    "    \"\"\"Drops all non-numeric columns (except your label col, if you want to keep it).\"\"\"\n",
    "    # Separate the label from the features\n",
    "    features_df = df.loc[:, df.columns != label_col]\n",
    "    label_series = df[label_col] if label_col in df.columns else None\n",
    "\n",
    "    # Keep only numeric columns\n",
    "    numeric_features_df = features_df.select_dtypes(include=[\"number\"]).copy()\n",
    "\n",
    "    # Reattach the label if present\n",
    "    if label_series is not None:\n",
    "        numeric_features_df[label_col] = label_series\n",
    "    \n",
    "    return numeric_features_df\n",
    "\n",
    "# Example usage:\n",
    "for dataset_name, df in datasets.items():\n",
    "    datasets[dataset_name] = drop_non_numeric_columns(df, label_col=\"Y\")\n",
    "\n",
    "\n",
    "for key, df in datasets.items():\n",
    "    if \"target\" in df.columns:\n",
    "        df.rename(columns={\"target\": \"Y\"}, inplace=True)\n",
    "import os\n",
    "\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    filename = os.path.join(\"dataset_files\", f\"{name}.pkl\")\n",
    "    df.to_pickle(filename)\n",
    "    print(f\"Saved {name} dataset as {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Define your model and selector lists\n",
    "model_types = [\n",
    "    \"LinearRegressionFunction\",\n",
    "    \"RandomForestRegressorFunction\",\n",
    "    \"XGBoostRegressorFunction\",\n",
    "    \"NeuralNetworkFunction\"\n",
    "]\n",
    "\n",
    "\n",
    "selector_types = [\n",
    "    \"PassiveLearning\",\n",
    "    \"GSxFunction\",            \n",
    "    \"GSxFunctionAverage\",      \n",
    "    \"GSyFunction\",              \n",
    "    \"GSyFunctionAverage\",     \n",
    "    \"iGSFunction\",             \n",
    "    \"iGSFunctionAverage\",     \n",
    "    \"iGSFunctionStandardized\", \n",
    "    \"iGSFunctionAverageStandardized\"\n",
    "]\n",
    "    \n",
    "# Import or define your OneIterationFunction and TrainTestCandidateSplit functions\n",
    "from utils.Main import OneIterationFunction, TrainTestCandidateSplit\n",
    "\n",
    "all_results = run_active_learning_experiments(\n",
    "    datasets=datasets,\n",
    "    model_types=model_types,\n",
    "    selector_types=selector_types,\n",
    "    OneIterationFunction=OneIterationFunction,\n",
    "    TrainTestCandidateSplit=TrainTestCandidateSplit,\n",
    "    n_simulations=2,          # Use 1 for a quick run; set 100+ for full experiments\n",
    "    test_proportion=0.2,\n",
    "    candidate_proportion=0.8,\n",
    "    plot=False,\n",
    "    do_wilcoxon=False,\n",
    "    round_wilcoxon=4,\n",
    "    output_dir=\"results\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def manual_active_learning_plot(results_summary, dataset_name, model_name, candidate_proportion=0.8):\n",
    "    \"\"\"\n",
    "    Manually plots the average error curves for all selectors\n",
    "    from results_summary for a specific (dataset_name, model_name).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_summary : dict\n",
    "        The dictionary returned by run_active_learning_experiments,\n",
    "        keyed by (dataset, model, selector).\n",
    "    dataset_name : str\n",
    "        The dataset key to plot (e.g. \"BostonHousing\").\n",
    "    model_name : str\n",
    "        The model key to plot (e.g. \"LinearRegressionFunction\").\n",
    "    candidate_proportion : float\n",
    "        Used to map the x-axis from initial training size up to 100%.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None (displays a matplotlib plot).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Gather all selectors for this dataset & model\n",
    "    #    simulation_error_dict will map { selector_name -> avg_error_array }\n",
    "    simulation_error_dict = {}\n",
    "    \n",
    "    for (ds, model, selector), info in results_summary.items():\n",
    "        if ds == dataset_name and model == model_name:\n",
    "            # info[\"avg_error\"] is the average error curve (numpy array) \n",
    "            simulation_error_dict[selector] = info[\"avg_error\"]\n",
    "    \n",
    "    # If no selectors found, just return\n",
    "    if not simulation_error_dict:\n",
    "        print(f\"No results found for dataset={dataset_name}, model={model_name}\")\n",
    "        return\n",
    "\n",
    "    # 2) Plot each selectors average error\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for selector_name, error_array in simulation_error_dict.items():\n",
    "        # M is how many AL iterations were performed\n",
    "        M = len(error_array)\n",
    "        \n",
    "        # Map iteration indices (0..M-1) to [start_percent..100]\n",
    "        # If candidate_proportion=0.8, then the training set eventually ends at 100% (all data).\n",
    "        # The starting percentage is 100*(1 - candidate_proportion) = 20% by default.\n",
    "        x_values = np.linspace(100*(1 - candidate_proportion), 100, M)\n",
    "\n",
    "        plt.plot(x_values, error_array, label=selector_name)\n",
    "\n",
    "    plt.title(f\"Active Learning Mean Error Plot\\n{dataset_name} with {model_name}\")\n",
    "    plt.xlabel(\"Percent of labelled observations\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# EXAMPLE USAGE:\n",
    "# Suppose you have the results_summary returned by run_active_learning_experiments.\n",
    "# You can call:\n",
    "\n",
    "manual_active_learning_plot(\n",
    "    results_summary=all_results, \n",
    "    dataset_name=\"Diabetes\",\n",
    "    model_name=\"LinearRegressionFunction\",\n",
    "    candidate_proportion=0.8  # or whatever you used in run_active_learning_experiments\n",
    ")\n",
    "manual_active_learning_plot(\n",
    "    results_summary=all_results, \n",
    "    dataset_name=\"Diabetes\",\n",
    "    model_name=\"RandomForestRegressorFunction\",\n",
    "    candidate_proportion=0.8  # or whatever you used in run_active_learning_experiments\n",
    ")\n",
    "manual_active_learning_plot(\n",
    "    results_summary=all_results, \n",
    "    dataset_name=\"Diabetes\",\n",
    "    model_name=\"XGBoostRegressorFunction\",\n",
    "    candidate_proportion=0.8  # or whatever you used in run_active_learning_experiments\n",
    ")\n",
    "manual_active_learning_plot(\n",
    "    results_summary=all_results, \n",
    "    dataset_name=\"Diabetes\",\n",
    "    model_name=\"NeuralNetworkFunction\",\n",
    "    candidate_proportion=0.8  # or whatever you used in run_active_learning_experiments\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rashomon-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
